{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Curso Transfer Learning\n",
        "\n",
        "<img src=\"https://yaelmanuel.com/wp-content/uploads/2021/12/platzi-banner-logo-matematicas.png\" width=\"500px\">\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "E4OEtECGjKtp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creando nuestro propio Clasificador de Im치genes 游꺙游꺕\n",
        "\n",
        "En este lab aprender치s:\n",
        "\n",
        "* [Pytorch](https://pytorch.org/)\n",
        "* [Torchvision](https://pytorch.org/vision/stable/index.html)\n",
        "* Descargar un dataset, prepararlo, entrenarlo, realizar finetuning y guardarlo.\n"
      ],
      "metadata": {
        "id": "p_ny9c9fjbLP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Descarga del dataset 游뱁\n",
        "\n",
        "Utilizaremos un conjunto de im치genes de enfermedades de las hojas de plantas.\n",
        "<br>Para m치s detalle ac치 se puede ver el dataset de Kaggle: [Plant disease Dataset](https://www.kaggle.com/datasets/rashikrahmanpritom/plant-disease-recognition-dataset).\n"
      ],
      "metadata": {
        "id": "fxgR3AqoTxQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle"
      ],
      "metadata": {
        "id": "5WVoiMyphoSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "Lv-i750ghtiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "kgDVQkKGibgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list -s plant-disease-classification"
      ],
      "metadata": {
        "id": "b9JJy0CIhxNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d rashikrahmanpritom/plant-disease-recognition-dataset"
      ],
      "metadata": {
        "id": "z10nbuiQh4av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/plant-disease-recognition-dataset.zip'"
      ],
      "metadata": {
        "id": "T-6HAPlAiza9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Creamos un folder \"enfermedades_hojas\" para guardar nuestras im치genes y mantener una estructura similar a la del ejemplo anterior.***"
      ],
      "metadata": {
        "id": "OI9-7yGNh0dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/enfermedades_hojas"
      ],
      "metadata": {
        "id": "JH-DTZuF2e5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Cambiamos el nombre de la carpeta \"validation\" por \"val\", para seguir la misma estructura del c칩digo de ejemplo***"
      ],
      "metadata": {
        "id": "O2kiOIrQniYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/Train/Train /content/enfermedades_hojas/train/\n",
        "!mv /content/Test/Test /content/enfermedades_hojas/test/\n",
        "!mv /content/Validation/Validation /content/enfermedades_hojas/val/"
      ],
      "metadata": {
        "id": "Bc9ia4ZMnwmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Removemos las carpetas vac칤as porque ya no los necesitamos.***"
      ],
      "metadata": {
        "id": "rKPTKQ7tmSWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/Test\n",
        "!rm -r /content/Train\n",
        "!rm -r /content/Validation"
      ],
      "metadata": {
        "id": "EoNOyz1M0bNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Preparaci칩n de la data 游녧"
      ],
      "metadata": {
        "id": "HX8Q_QXsTts3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1) Instalamos las dependencias 游뗿"
      ],
      "metadata": {
        "id": "BYa0Tjnv74mE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.models import ResNet50_Weights, VGG19_Weights, MobileNet_V2_Weights\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy"
      ],
      "metadata": {
        "id": "Xu_qILeYSLv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2) Tips de implementaci칩n 游"
      ],
      "metadata": {
        "id": "LghPjoil8Njr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "d3OFpYzd5umr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "tSuVNQanVrUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3) Data Augmentation 游닝 游닞"
      ],
      "metadata": {
        "id": "aEVRaI1Q8ayz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "metadata": {
        "id": "fzd7EpuaVj_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.4) Dataset, Dataloader y m치s data 游댌"
      ],
      "metadata": {
        "id": "Ull0vjyr9Ihl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "DSj6JT8QWbtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'enfermedades_hojas'\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])for x in ['train', 'val']}\n",
        "\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=2) for x in ['train', 'val']}\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "\n",
        "class_names = image_datasets['train'].classes"
      ],
      "metadata": {
        "id": "2EmQl-jvV93M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow para tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # Pausarlo un poco para que se actualicen los plots\n",
        "\n",
        "\n",
        "# Obtener un batch de datos de entrenamiento\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "# Crear una grilla con las im치genes\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ],
      "metadata": {
        "id": "BTG-jSTXW2FS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Evaluar las class_names***"
      ],
      "metadata": {
        "id": "3RrtVT0bUYA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(class_names)"
      ],
      "metadata": {
        "id": "uVOIoRBdUVCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Entrenamiento 游눩"
      ],
      "metadata": {
        "id": "z5CReMaiYSDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Cada epoch tiene una fase de entrenamiento y validaci칩n.\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Fase entrenamiento\n",
        "            else:\n",
        "                model.eval()   # Fase validaci칩n\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterar sobre la data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history solo si es la fase de entrenamiento\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize solo si es la fase de entrenamiento\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # Estad칤sticas\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy el modelo\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # Cargar el best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "metadata": {
        "id": "lIq8l9BeYUG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "metadata": {
        "id": "y1JuSJraYiQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) Finetuning de la convnet 游땯"
      ],
      "metadata": {
        "id": "NdRZS4ZactJU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.1) Resnet50"
      ],
      "metadata": {
        "id": "1SX3R0IEoMcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft__resnet = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
        "num_ftrs = model_ft__resnet.fc.in_features"
      ],
      "metadata": {
        "id": "cLqzI2RNRnPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reemplazar la capa final\n",
        "# Aqu칤 el tama침o de cada muestra de salida se establece en len(class_names) = 3.\n",
        "model_ft__resnet.fc = nn.Linear(num_ftrs, len(class_names))\n",
        "\n",
        "model_ft__resnet = model_ft__resnet.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe que todos los par치metros est치n siendo optimizados\n",
        "optimizer_ft = optim.SGD(model_ft__resnet.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decae LR por un factor de 0.1 cada 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "E1dwcF05Ynf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Vamos a usar 5 epochs***"
      ],
      "metadata": {
        "id": "OSjLPIucUu9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft__resnet = train_model(model_ft__resnet, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=5)"
      ],
      "metadata": {
        "id": "BfK-CwxoGlWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_model(model_ft__resnet)"
      ],
      "metadata": {
        "id": "WnTpR4fkYy6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardar el modelo"
      ],
      "metadata": {
        "id": "VHn0lg0noYZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_ft__resnet, \"model_resnet50.pth\")"
      ],
      "metadata": {
        "id": "smrjR0-xoZ0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nota: El archivo de este modelo entrenado pesa 90 MB."
      ],
      "metadata": {
        "id": "1ADXaHdp-tBG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.2) Resnet50 + Custom Layers"
      ],
      "metadata": {
        "id": "xLlfMZffy0p3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft__custom = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
        "num_ftrs = model_ft__custom.fc.in_features"
      ],
      "metadata": {
        "id": "BruIuQQq_37p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definir un nuevo clasificador con una capa Dropout adicional"
      ],
      "metadata": {
        "id": "XQLIINqgAYmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft__custom.fc = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 512),       # A침adir una capa lineal intermedia\n",
        "    nn.ReLU(),                      # Activaci칩n no lineal\n",
        "    nn.Dropout(0.5),                # Dropout con probabilidad de 0.5\n",
        "    nn.Linear(512, len(class_names))  # Capa final adaptada al n칰mero de clases\n",
        ")\n",
        "\n",
        "model_ft__custom = model_ft__custom.to(device)"
      ],
      "metadata": {
        "id": "22T7aLtdAAKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe que todos los par치metros est치n siendo optimizados\n",
        "optimizer_ft = optim.SGD(model_ft__custom.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decae LR por un factor de 0.1 cada 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "ZLVhUtpKARgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Vamos a usar 5 epochs***"
      ],
      "metadata": {
        "id": "d0VCSmKGAc3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft__custom = train_model(model_ft__custom, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=5)"
      ],
      "metadata": {
        "id": "A3uBwZR4AdNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_model(model_ft__custom)"
      ],
      "metadata": {
        "id": "Y2xaHOvZAmd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardar el modelo"
      ],
      "metadata": {
        "id": "3irP13K4Ap8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_ft__custom, \"model_custom.pth\")"
      ],
      "metadata": {
        "id": "5z4GDRjlAtnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nota: El archivo de este modelo entrenado pesa 94 MB."
      ],
      "metadata": {
        "id": "CteFd12DA0Ky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.3) VGG19"
      ],
      "metadata": {
        "id": "CHhBjMQWu58-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft__vgg19 = models.vgg19(weights=VGG19_Weights.IMAGENET1K_V1)\n",
        "num_ftrs = model_ft__vgg19.classifier[6].in_features"
      ],
      "metadata": {
        "id": "jZGFOaVMOgN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reemplazar la capa final\n",
        "# Aqu칤 el tama침o de cada muestra de salida se establece en len(class_names) = 3.\n",
        "model_ft__vgg19.classifier[6] = nn.Linear(num_ftrs, len(class_names))\n",
        "\n",
        "model_ft__vgg19 = model_ft__vgg19.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe que todos los par치metros est치n siendo optimizados\n",
        "optimizer_ft = optim.SGD(model_ft__vgg19.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decae LR por un factor de 0.1 cada 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "kTYdm60y1Hc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Vamos a usar 5 epochs***"
      ],
      "metadata": {
        "id": "TOUeJQ2t1tc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft__vgg19 = train_model(model_ft__vgg19, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=5)"
      ],
      "metadata": {
        "id": "dn_KfDPh1wZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_model(model_ft__vgg19)"
      ],
      "metadata": {
        "id": "hD_cW_gM4PFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardar el modelo"
      ],
      "metadata": {
        "id": "pgfwJqZH4QEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_ft__vgg19, \"model_vgg19.pth\")"
      ],
      "metadata": {
        "id": "V57cZmkI4Mej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nota: El archivo de este modelo entrenado pesa 532 MB."
      ],
      "metadata": {
        "id": "qyMUd1Ci-0ah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.4) Mobilenet v2"
      ],
      "metadata": {
        "id": "eD8ti85zy5Wi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft__mobilenetv2 = models.mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V2)\n",
        "num_ftrs = model_ft__mobilenetv2.last_channel"
      ],
      "metadata": {
        "id": "Vokxm0tX6QF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reemplazar la capa final\n",
        "# Aqu칤 el tama침o de cada muestra de salida se establece en len(class_names) = 3.\n",
        "model_ft__mobilenetv2.classifier[1] = nn.Linear(num_ftrs, len(class_names))\n",
        "\n",
        "model_ft__mobilenetv2 = model_ft__mobilenetv2.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe que todos los par치metros est치n siendo optimizados\n",
        "optimizer_ft = optim.SGD(model_ft__mobilenetv2.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decae LR por un factor de 0.1 cada 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "gB-4M6P76ZJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Vamos a usar 5 epochs***"
      ],
      "metadata": {
        "id": "VNNV4lFj6jKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft__mobilenetv2 = train_model(model_ft__mobilenetv2, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=5)"
      ],
      "metadata": {
        "id": "i9V669SVQ3pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_model(model_ft__mobilenetv2)"
      ],
      "metadata": {
        "id": "isAEYfgT6roQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardar el modelo"
      ],
      "metadata": {
        "id": "mnPvYnfO9rQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_ft__mobilenetv2, \"model_mobilenetv2.pth\")"
      ],
      "metadata": {
        "id": "JyGopEEE60LQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nota: El archivo de este modelo entrenado pesa ~9 MB."
      ],
      "metadata": {
        "id": "dsPzdC74-8ee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5) Hacer Predicciones en Producci칩n 游뱇"
      ],
      "metadata": {
        "id": "icAp1SniSDuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "EO32eWWZSEPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar el modelo una vez (al inicio de la aplicaci칩n)"
      ],
      "metadata": {
        "id": "SRtZXB8LSRw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determinar el dispositivo\n",
        "mi_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Cargar el modelo en el dispositivo\n",
        "mi_modelo = torch.load(\"model_mobilenetv2.pth\", map_location=mi_device, weights_only=False)\n",
        "mi_modelo.eval()\n",
        "mi_modelo.to(mi_device)"
      ],
      "metadata": {
        "id": "vGkV7b_ISSqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funci칩n para predicci칩n / inferencia"
      ],
      "metadata": {
        "id": "7vhsu1naSWb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(image_path, model, class_names, device):\n",
        "    \"\"\"\n",
        "    Predice la clase de una imagen usando un modelo entrenado.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Ruta de la imagen.\n",
        "        model (torch.nn.Module): Modelo ya cargado y configurado para inferencia.\n",
        "        class_names (list): Lista de nombres de clases.\n",
        "        device (torch.device): Dispositivo donde est치 el modelo.\n",
        "\n",
        "    Returns:\n",
        "        str: Clase predicha.\n",
        "    \"\"\"\n",
        "    # Preprocesamiento de la imagen\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Cargar y preprocesar la imagen\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image_tensor = preprocess(image).unsqueeze(0).to(device)  # A침adir dimensi칩n batch y mover al dispositivo\n",
        "\n",
        "    # Realizar predicci칩n\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image_tensor)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    # Retornar la clase predicha\n",
        "    return class_names[preds[0].item()]"
      ],
      "metadata": {
        "id": "Et4wFh3ISZK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejemplos de uso"
      ],
      "metadata": {
        "id": "3gkxguDSSc-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['Healthy', 'Powdery', 'Rust']"
      ],
      "metadata": {
        "id": "I0Bfi7PHSeRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_image = \"/content/enfermedades_hojas/val/Rust/8030a3a79fca6abb.jpg\"\n",
        "\n",
        "predicted_class = predict_image(path_image, mi_modelo, class_names, mi_device)\n",
        "print(f\"La clase predicha es: {predicted_class}\")"
      ],
      "metadata": {
        "id": "uE3J0K9ESzcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_image = \"/content/enfermedades_hojas/val/Healthy/9c3f1c10ba54ed56.jpg\"\n",
        "\n",
        "predicted_class = predict_image(path_image, mi_modelo, class_names, mi_device)\n",
        "print(f\"La clase predicha es: {predicted_class}\")"
      ],
      "metadata": {
        "id": "9Ugk46POS19t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_image = \"/content/enfermedades_hojas/val/Powdery/8f6737815b2cd234.jpg\"\n",
        "\n",
        "predicted_class = predict_image(path_image, mi_modelo, class_names, mi_device)\n",
        "print(f\"La clase predicha es: {predicted_class}\")"
      ],
      "metadata": {
        "id": "o3GYERUhS2Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6) Conclusiones\n",
        "\n",
        "- Aprender sobre los distintos objetos y m칠todos que nos ofrece Pytorch / Torchvision.\n",
        "\n",
        "- Realizar el proceso completo de clasificaci칩n de im치genes con Pytorch.\n",
        "\n",
        "- Aprender tips sobre implementaci칩n con el uso de la GPU.\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "<br>"
      ],
      "metadata": {
        "id": "Wl7v6oyFkREF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "<img src=\"https://static.platzi.com/media/avatars/platziteam_8cfe6fc7-1246-4c9a-9f5d-d10d467443ee.png\" width=\"100px\">\n",
        "\n",
        "[Platzi](https://platzi.com/) 游\n",
        "\n"
      ],
      "metadata": {
        "id": "0sQ95LlzkUZN"
      }
    }
  ]
}